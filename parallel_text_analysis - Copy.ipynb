{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from IPython.display import display # Good practice to import display\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# -----------------------------------------------------\n",
        "# 2Ô∏è‚É£  Helper functions\n",
        "# -----------------------------------------------------\n",
        "\n",
        "WORD_RE = re.compile(r\"\\b[a-zA-Z']+\\b\")\n",
        "\n",
        "def clean_and_tokenize(text: str):\n",
        "    \"\"\"Lowercase and tokenize into simple alphabetic words.\"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    return WORD_RE.findall(text.lower())\n",
        "\n",
        "def process_chunk(lines):\n",
        "    \"\"\"Process one chunk of reviews and return local Counter.\"\"\"\n",
        "    local_counter = Counter()\n",
        "    for text in lines:\n",
        "        local_counter.update(clean_and_tokenize(text))\n",
        "    return local_counter\n",
        "\n",
        "def chunkify(lst, n):\n",
        "    \"\"\"Split a list into n nearly equal chunks.\"\"\"\n",
        "    k, m = divmod(len(lst), n)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    for i in range(n):\n",
        "        size = k + (1 if i < m else 0)\n",
        "        chunks.append(lst[start:start+size])\n",
        "        start += size\n",
        "    return chunks\n",
        "\n",
        "def run_sequential(reviews):\n",
        "    \"\"\"Run single-threaded baseline.\"\"\"\n",
        "    t0 = time.time()\n",
        "    counter = process_chunk(reviews)\n",
        "    t1 = time.time()\n",
        "    return counter, t1 - t0\n",
        "\n",
        "def run_parallel(reviews, n_workers):\n",
        "    \"\"\"Run multi-process text counting.\"\"\"\n",
        "    chunks = chunkify(reviews, n_workers)\n",
        "    t0 = time.time()\n",
        "    with Pool(processes=n_workers) as p:\n",
        "        results = list(tqdm(p.imap(process_chunk, chunks), total=len(chunks),\n",
        "                            desc=f\"{n_workers} workers\"))\n",
        "    total = Counter()\n",
        "    for r in results:\n",
        "        total.update(r)\n",
        "    t1 = time.time()\n",
        "    return total, t1 - t0\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3Ô∏è‚É£  Load dataset\n",
        "# -----------------------------------------------------\n",
        "# Note: Make sure '/content/IMDB Dataset.csv' is the correct path\n",
        "# after mounting your drive. You might need to adjust this to\n",
        "# '/content/drive/My Drive/path/to/IMDB Dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "    reviews = df['review'].astype(str).tolist()\n",
        "    print(f\"üìä Loaded {len(reviews):,} reviews\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: 'IMDB Dataset.csv' not found at '/content/'.\")\n",
        "    print(\"Please make sure the path is correct, or upload the file.\")\n",
        "    reviews = [] # Set to empty list to avoid further errors\n",
        "\n",
        "if reviews:\n",
        "    # -----------------------------------------------------\n",
        "    # 4Ô∏è‚É£  Sequential baseline\n",
        "    # -----------------------------------------------------\n",
        "    print(\"\\n‚öôÔ∏è Running sequential baseline...\")\n",
        "    seq_counter, seq_time = run_sequential(reviews)\n",
        "    print(f\"‚úÖ Sequential processing time: {seq_time:.3f} s\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 5Ô∏è‚É£  Parallel runs\n",
        "    # -----------------------------------------------------\n",
        "    results = []\n",
        "    results.append({\"workers\": 1, \"time\": seq_time, \"speedup\": 1.0, \"efficiency\": 100.0})\n",
        "\n",
        "    # Use a sensible number of workers, e.g., up to the number of CPUs\n",
        "    max_workers = cpu_count()\n",
        "    print(f\"üñ•Ô∏è Detected {max_workers} CPUs\")\n",
        "\n",
        "    # Let's test 2, 4, and 8, but only if <= max_workers\n",
        "    for w in [2, 4, 8]:\n",
        "        if w <= max_workers:\n",
        "            print(f\"\\nüöÄ Running with {w} workers...\")\n",
        "            counter, t = run_parallel(reviews, w)\n",
        "            speedup = seq_time / t\n",
        "            efficiency = 100.0 * speedup / w\n",
        "            results.append({\n",
        "                \"workers\": w,\n",
        "                \"time\": t,\n",
        "                \"speedup\": speedup,\n",
        "                \"efficiency\": efficiency\n",
        "            })\n",
        "        else:\n",
        "            print(f\"\\n‚ÑπÔ∏è Skipping {w} workers (more than available CPUs).\")\n",
        "\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 6Ô∏è‚É£  Display results table\n",
        "    # -----------------------------------------------------\n",
        "    print(\"\\nüìà Performance Results:\")\n",
        "    res_df = pd.DataFrame(results)\n",
        "\n",
        "    # --- THIS IS THE FIX ---\n",
        "    # .hide_index() was removed in pandas 2.0. Use .hide(axis=\"index\") instead.\n",
        "    display(res_df.style.format({\n",
        "        \"time\": \"{:.3f}\",\n",
        "        \"speedup\": \"{:.2f}\",\n",
        "        \"efficiency\": \"{:.1f}\"\n",
        "    }).hide(axis=\"index\"))\n",
        "    # --- END OF FIX ---\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 7Ô∏è‚É£  Show top 15 most common words\n",
        "    # -----------------------------------------------------\n",
        "    print(\"\\nüìù Top 15 words (sequential run):\")\n",
        "    for word, count in seq_counter.most_common(15):\n",
        "        print(f\"{word:<15} {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "bNqsaNCbPCiF",
        "outputId": "89999719-bff8-4052-a69e-0051dc530bb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìä Loaded 50,000 reviews\n",
            "\n",
            "‚öôÔ∏è Running sequential baseline...\n",
            "‚úÖ Sequential processing time: 7.053 s\n",
            "üñ•Ô∏è Detected 2 CPUs\n",
            "\n",
            "üöÄ Running with 2 workers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2 workers: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ÑπÔ∏è Skipping 4 workers (more than available CPUs).\n",
            "\n",
            "‚ÑπÔ∏è Skipping 8 workers (more than available CPUs).\n",
            "\n",
            "üìà Performance Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x791cb028bc80>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_5872a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_5872a_level0_col0\" class=\"col_heading level0 col0\" >workers</th>\n",
              "      <th id=\"T_5872a_level0_col1\" class=\"col_heading level0 col1\" >time</th>\n",
              "      <th id=\"T_5872a_level0_col2\" class=\"col_heading level0 col2\" >speedup</th>\n",
              "      <th id=\"T_5872a_level0_col3\" class=\"col_heading level0 col3\" >efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_5872a_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_5872a_row0_col1\" class=\"data row0 col1\" >7.053</td>\n",
              "      <td id=\"T_5872a_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_5872a_row0_col3\" class=\"data row0 col3\" >100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5872a_row1_col0\" class=\"data row1 col0\" >2</td>\n",
              "      <td id=\"T_5872a_row1_col1\" class=\"data row1 col1\" >5.614</td>\n",
              "      <td id=\"T_5872a_row1_col2\" class=\"data row1 col2\" >1.26</td>\n",
              "      <td id=\"T_5872a_row1_col3\" class=\"data row1 col3\" >62.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Top 15 words (sequential run):\n",
            "the             667984\n",
            "and             324440\n",
            "a               322940\n",
            "of              289407\n",
            "to              268108\n",
            "is              211075\n",
            "br              201951\n",
            "in              186770\n",
            "it              157026\n",
            "i               155108\n",
            "this            150992\n",
            "that            137061\n",
            "was             95594\n",
            "as              91748\n",
            "for             87471\n"
          ]
        }
      ]
    }
  ]
}